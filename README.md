# tbd ‚Äî tiny, but distributed

A **tiny, but real distributed system** built for learning and demonstration purposes.  
It uses **Go**, **PostgreSQL**, **Kafka**, and **Docker Compose** to showcase API design, event-driven processing, observability, and idempotency.

---

## üß© Overview

`tbd` simulates a simple **Order Processing System** ‚Äî small enough to run locally, but rich enough to demonstrate real distributed system concepts:

- RESTful API
- PostgreSQL database
- Kafka-based event stream
- Background worker for async processing
- OpenTelemetry tracing + Prometheus metrics + Grafana dashboards
- Jaeger for distributed tracing
- pgAdmin and Kafka UI for observability

---

## ‚öôÔ∏è Architecture

```mermaid
flowchart LR
    %% Overall direction
    %% Styles (optional; safe defaults)
    classDef client fill:#eef,stroke:#88a;
    classDef services fill:#eefeef,stroke:#6a6;
    classDef messaging fill:#fff6dd,stroke:#cc9;
    classDef data fill:#e8f2ff,stroke:#59a;
    classDef observ fill:#f5f5f5,stroke:#999;

    %% Client
    subgraph client[Client]
        direction TB
        k6["k6 Load Tester"]:::client
    end

    %% Load Balancer
    subgraph lb[Load Balancer]
        direction TB
        nginx["Nginx<br/>(Round-robin)"]:::services
    end

    %% Core services
    subgraph services[Services]
        direction TB
        api["API (Go)<br/>REST<br/>(scalable)"]:::services
        worker["Worker<br/>(Kafka Consumer/Producer)<br/>(scalable)"]:::services
    end

    %% Messaging
    subgraph msg[Messaging]
        direction TB
        kafka[("(Kafka)<br/>order.created / order.processed")]:::messaging
    end

    %% Data
    subgraph data[Data]
        direction TB
        postgres["Postgres"]:::data
    end

    %% Observability
    subgraph obs[Observability]
        direction TB
        otel["OpenTelemetry Collector"]:::observ
        jaeger["Jaeger"]:::observ
        prometheus["Prometheus"]:::observ
        grafana["Grafana"]:::observ
        pgadmin["pgAdmin"]:::observ
        kafkaui["Kafka UI"]:::observ
    end

    %% Happy-path flow
    k6 --> nginx
    nginx --> api
    api -->|"(1) Write order"| postgres
    api -->|"(2) Publish order.created"| kafka
    kafka --> worker
    worker -->|"(3) Update status"| postgres
    worker -->|"(4) Emit order.processed"| kafka

    %% Telemetry & UIs
    api -->|"Traces & metrics"| otel
    worker -->|"Traces & metrics"| otel
    otel --> jaeger
    otel --> prometheus
    prometheus --> grafana
    postgres --> pgadmin
    kafka --> kafkaui
```

---

## üß† Core Concepts

### Entities
**Order**
```json
{
  "id": "uuid",
  "customer_email": "user@example.com",
  "amount_cents": 1299,
  "status": "pending|processing|completed|failed|canceled",
  "created_at": "...",
  "updated_at": "..."
}
```

---

## üöÄ Components (Docker Compose)

| Service         | Purpose |
|-----------------|----------|
| **nginx**       | Load balancer for API instances on port `8080` |
| **api**         | Go REST API, exposes `/v1/orders` endpoints (scalable) |
| **worker**      | Kafka consumer/producer; processes `order.created` events (scalable) |
| **postgres**    | Relational DB for orders |
| **pgadmin**     | Database UI on port `5050` |
| **kafka**       | Message broker (single-node cluster or Redpanda) |
| **kafka-ui**    | Kafka topic browser on port `8082` |
| **otel-collector** | Receives traces/metrics from services |
| **jaeger**      | Distributed tracing UI on port `16686` |
| **prometheus**  | Metrics collection on port `9090` |
| **grafana**     | Dashboards on port `3000` |

---

## üåê API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/healthz` | Liveness check |
| `GET` | `/readyz` | Readiness (checks DB + Kafka) |
| `GET` | `/metrics` | Prometheus scrape endpoint |
| `POST` | `/v1/orders` | Create order (requires `Idempotency-Key`; see details below) |
| `GET` | `/v1/orders/{id}` | Retrieve order by ID |
| `GET` | `/v1/orders` | List orders (`?status=&page=&page_size=`) |
| `POST` | `/v1/orders/{id}/cancel` | Cancel pending order |

---

## üîÅ Idempotency for POST /v1/orders

Use an `Idempotency-Key` header for **POST /v1/orders** to ensure safe retries.

**Example:**
```bash
curl -X POST http://localhost:8080/v1/orders   -H "Content-Type: application/json"   -H "Idempotency-Key: $(uuidgen)"   -d '{"customer_email":"a@b.com","amount_cents":1234}'
```

### How it works
- The API stores `{ key, request_hash, response, order_id }` for each key.
- Repeated calls with the same key **replay** the original response.
- Prevents duplicate orders on network retries.
- TTL for dedup cache: 24‚Äì72h (configurable).

> **Note:** `Idempotency-Key` ‚â† `If-Match`.  
> `If-Match` (with ETags) handles concurrency for updates.  
> `Idempotency-Key` deduplicates **retries** of the same create request.

---

## üîÑ Kafka Topics

| Topic | Description |
|--------|-------------|
| `order.created` | Emitted by API when a new order is created |
| `order.processed` | Emitted by Worker after successful processing |

**Future topics** (for robust error handling):
- `order.failed` ‚Äî Emitted by Worker on processing failure
- `order.dlq` ‚Äî Dead letter queue for poison messages after max retries

---

## üß∞ Local Development

### Prerequisites
- Docker + Docker Compose
- Go ‚â• 1.22
- make (optional)
- k6 (for load testing)

### Run everything
```bash
docker compose up --build
```

Check UIs:
- API ‚Üí [http://localhost:8080](http://localhost:8080)
- pgAdmin ‚Üí [http://localhost:5050](http://localhost:5050)
- Kafka UI ‚Üí [http://localhost:8082](http://localhost:8082)
- Jaeger ‚Üí [http://localhost:16686](http://localhost:16686)
- Prometheus ‚Üí [http://localhost:9090](http://localhost:9090)
- Grafana ‚Üí [http://localhost:3000](http://localhost:3000)

---

## üóÉÔ∏è Database Migrations

This project uses [**golang-migrate/migrate**](https://github.com/golang-migrate/migrate) for database schema versioning and migrations.

### Installation

**macOS:**
```bash
brew install golang-migrate
```

**Linux:**
```bash
curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz | tar xvz
sudo mv migrate /usr/local/bin/
```

**Go install:**
```bash
go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@latest
```

### Running Migrations

**Apply all pending migrations:**
```bash
migrate -path migrations \
  -database "postgres://tbd:secret@localhost:5432/tbd?sslmode=disable" \
  up
```

**Rollback last migration:**
```bash
migrate -path migrations \
  -database "postgres://..." \
  down 1
```

**Check migration version:**
```bash
migrate -path migrations \
  -database "postgres://..." \
  version
```

### Creating New Migrations

```bash
migrate create -ext sql -dir migrations -seq create_payments_table
```

This generates:
- `000003_create_payments_table.up.sql` (apply changes)
- `000003_create_payments_table.down.sql` (rollback changes)

### Automated Migrations

The API automatically runs pending migrations on startup (see `cmd/api/main.go` for the initialization logic).

**Disable auto-migration** for production by setting:
```bash
AUTO_MIGRATE=false
```

---

## ‚öôÔ∏è Configuration

Services are configured via **environment variables**. See `docker-compose.yml` for the complete setup.

### API Service

| Variable | Default | Description |
|----------|---------|-------------|
| `API_PORT` | `8080` | HTTP server port |
| `LOG_LEVEL` | `info` | Log level: `debug`, `info`, `warn`, `error` |
| `DB_HOST` | `localhost` | PostgreSQL host |
| `DB_PORT` | `5432` | PostgreSQL port |
| `DB_USER` | `tbd` | Database user |
| `DB_PASSWORD` | `secret` | Database password |
| `DB_NAME` | `tbd` | Database name |
| `DB_MAX_CONNS` | `25` | Maximum database connections |
| `DB_MAX_IDLE_CONNS` | `5` | Maximum idle database connections |
| `DB_CONN_MAX_LIFETIME` | `5m` | Maximum connection lifetime |
| `KAFKA_BROKERS` | `localhost:9092` | Comma-separated Kafka broker addresses |
| `KAFKA_TOPIC_ORDER_CREATED` | `order.created` | Topic for order creation events |
| `KAFKA_TOPIC_ORDER_PROCESSED` | `order.processed` | Topic for order processed events |
| `IDEMPOTENCY_TTL` | `72h` | Time-to-live for idempotency keys (24h‚Äì168h) |
| `AUTO_MIGRATE` | `true` | Run database migrations on startup |
| `OTEL_EXPORTER_OTLP_ENDPOINT` | `localhost:4317` | OpenTelemetry collector endpoint |
| `OTEL_SERVICE_NAME` | `tbd-api` | Service name for traces/metrics |

### Worker Service

| Variable | Default | Description |
|----------|---------|-------------|
| `LOG_LEVEL` | `info` | Log level |
| `DB_HOST` | `localhost` | PostgreSQL host |
| `DB_PORT` | `5432` | PostgreSQL port |
| `DB_USER` | `tbd` | Database user |
| `DB_PASSWORD` | `secret` | Database password |
| `DB_NAME` | `tbd` | Database name |
| `KAFKA_BROKERS` | `localhost:9092` | Kafka broker addresses |
| `KAFKA_CONSUMER_GROUP` | `tbd-workers` | Consumer group ID for worker instances |
| `KAFKA_TOPIC_ORDER_CREATED` | `order.created` | Topic to consume from |
| `KAFKA_TOPIC_ORDER_PROCESSED` | `order.processed` | Topic to publish to |
| `WORKER_CONCURRENCY` | `5` | Number of concurrent message processors |
| `OTEL_EXPORTER_OTLP_ENDPOINT` | `localhost:4317` | OpenTelemetry collector endpoint |
| `OTEL_SERVICE_NAME` | `tbd-worker` | Service name for traces/metrics |

### Example `.env` File

```bash
# Database
DB_HOST=postgres
DB_PORT=5432
DB_USER=tbd
DB_PASSWORD=secret
DB_NAME=tbd

# Kafka
KAFKA_BROKERS=kafka:9092

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
LOG_LEVEL=debug

# API-specific
API_PORT=8080
IDEMPOTENCY_TTL=72h
AUTO_MIGRATE=true

# Worker-specific
KAFKA_CONSUMER_GROUP=tbd-workers
WORKER_CONCURRENCY=5
```

---

## üìà Observability

| Component | Tool | Notes |
|------------|------|-------|
| Tracing | **OpenTelemetry + Jaeger** | Follow request ‚Üí event ‚Üí processing trace |
| Metrics | **Prometheus + Grafana** | HTTP latency, Kafka lag, worker stats |
| Logs | **Structured JSON** | Includes `trace_id`, `span_id`, `order_id` |

**Key Metrics to Monitor:**
- `http_request_duration_seconds` ‚Äî API endpoint latency (P50, P95, P99)
- `http_requests_total` ‚Äî Request count by status code
- `kafka_producer_latency_seconds` ‚Äî Time to publish events
- `kafka_consumer_lag` ‚Äî Consumer group lag per partition
- `db_query_duration_seconds` ‚Äî Database query performance
- `orders_created_total` ‚Äî Business metric: orders created
- `orders_processed_total` ‚Äî Business metric: orders processed
- `idempotency_hits_total` ‚Äî Duplicate request prevention rate

---

## ‚ö†Ô∏è Error Handling & Resilience

This project demonstrates production-ready error handling and resilience patterns.

### Retry Strategy

| Operation | Retries | Backoff | Notes |
|-----------|---------|---------|-------|
| **Kafka publish** | 3 | Exponential: 100ms ‚Üí 500ms ‚Üí 2s | API fails request if Kafka unavailable |
| **DB queries** | 3 | Linear: 50ms intervals | Automatic retry on transient errors (connection loss, deadlock) |
| **Worker message processing** | ‚àû | At-least-once delivery | Kafka consumer auto-commits only on success |

### Timeouts

| Component | Timeout | Rationale |
|-----------|---------|-----------|
| **HTTP request** | 30s | Prevents client hanging indefinitely |
| **DB query** | 5s | Fails fast on slow queries |
| **Kafka publish** | 10s | Allows retries but prevents indefinite blocking |
| **Worker processing** | 60s | Per-message processing limit |
| **Graceful shutdown** | 30s | Finish in-flight requests before terminating |

### Failure Modes & Handling

#### **Kafka Unavailable**
- **API behavior**: Returns `503 Service Unavailable`
- **Readiness check**: `/readyz` fails ‚Üí load balancer stops routing traffic
- **Worker behavior**: Stops consuming, waits for reconnection
- **Recovery**: Auto-reconnects when Kafka comes back online

#### **Database Unavailable**
- **API behavior**: `/readyz` fails immediately
- **Worker behavior**: Stops processing, retries DB connection
- **Recovery**: Connection pool auto-reconnects

#### **Worker Crash Mid-Processing**
- **Kafka behavior**: Consumer group rebalances partitions
- **Message replay**: Another worker re-processes the message from last commit
- **Idempotency**: Duplicate processing is safe (idempotency keys prevent duplicate orders)

#### **Poison Message** (Future)
- **Current**: Worker retries indefinitely (can cause consumer lag)
- **Planned**: After 3 failed attempts, publish to `order.dlq` topic
- **Manual review**: DLQ messages require investigation

### Idempotency Guarantees

- **POST /v1/orders**: Uses `Idempotency-Key` header to prevent duplicate orders
- **Worker processing**: Updates are idempotent (setting status to "processed" multiple times is safe)
- **Event publishing**: Kafka's at-least-once delivery + idempotent consumers ensure exactly-once semantics

### Circuit Breaker (Future Enhancement)

Planned for external API calls or slow dependencies:
- **Threshold**: 5 consecutive failures ‚Üí open circuit
- **Half-open retry**: After 30s cooldown
- **Monitoring**: Expose `circuit_breaker_state` metric

### Distributed Tracing for Errors

- All errors include `trace_id` and `span_id` for correlation
- Failed requests are visible in Jaeger with error tags
- Worker failures show full trace: API ‚Üí Kafka ‚Üí Worker ‚Üí DB

---

## üß™ Load Testing (k6)

Example script: `loadtest/orders.js`
```javascript
import http from 'k6/http';
import { check } from 'k6';
import { uuidv4 } from 'https://jslib.k6.io/k6-utils/1.4.0/index.js';

export let options = { vus: 20, duration: '30s' };

export default function () {
  const headers = {
    'Content-Type': 'application/json',
    'Idempotency-Key': uuidv4(),
  };
  const body = JSON.stringify({
    customer_email: `user${__VU}@example.com`,
    amount_cents: 1999,
  });

  const res = http.post('http://localhost:8080/v1/orders', body, { headers });
  check(res, { 'status 202': (r) => r.status === 202 });
}
```

Run:
```bash
k6 run loadtest/orders.js
```

---

## üîç Logs & Monitoring

```bash
# Tail service logs
docker compose logs -f api
docker compose logs -f worker

# Inspect recent Kafka messages
docker exec -it kafka kafka-console-consumer   --bootstrap-server localhost:9092 --topic order.created --from-beginning
```

---

## üßÆ Scaling Locally

You can simulate a true distributed system by running multiple service replicas:

```bash
docker compose up --scale api=3 --scale worker=3
```

**How it works:**
- **API scaling**: Nginx load balancer distributes requests across all API instances (round-robin)
- **Worker scaling**: Kafka consumer groups automatically distribute partitions across all worker instances
- **Database**: Single PostgreSQL instance (write scaling requires read replicas or sharding, beyond this demo's scope)

All requests still go through `http://localhost:8080` (nginx), which transparently load balances to the API instances.

**Observing distributed behavior:**
- Check nginx load balancing: `docker compose logs -f nginx`
- Monitor Kafka partition assignment: Open Kafka UI at http://localhost:8082
- Watch worker coordination: `docker compose logs -f worker`

For advanced simulation:
- Add artificial latency with `tc netem`
- Kill a worker to observe partition rebalancing: `docker compose kill tbd-worker-1`
- Kill an API instance to observe load balancer failover: `docker compose kill tbd-api-1`
- Stop Kafka briefly and observe retry/backpressure: `docker compose stop kafka`

---

## üîß Future Extensions

| Feature | Description |
|----------|-------------|
| **gRPC API** | Mirror the REST endpoints using Protobuf |
| **ghz testing** | Benchmark gRPC latency and throughput |
| **Outbox pattern** | Atomic DB write + event publish |
| **Saga orchestration** | Multi-step distributed workflows |
| **Service auth** | mTLS or JWT for inter-service calls |
| **Kubernetes** | Run the same topology with k3d or kind |

---

## üìÇ Directory Structure

```
tbd/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # API entrypoint: wires HTTP server + use cases + adapters
‚îÇ   ‚îî‚îÄ‚îÄ worker/                    # Worker entrypoint: wires Kafka consumer + use cases
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ orders/                    # Orders bounded context
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ order.go           # Order entity (aggregate root)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status.go          # Status value object
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events.go          # Domain events (OrderCreated, OrderProcessed, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ create_order.go       # CreateOrderHandler
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cancel_order.go       # CancelOrderHandler
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mark_processed.go     # MarkProcessedHandler
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queries/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ get_order.go          # GetOrderHandler
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ list_orders.go        # ListOrdersHandler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ports/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository.go      # OrderRepository interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event_bus.go       # EventBus interface (generic, tech-agnostic)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ idempotency.go     # IdempotencyStore interface (generic)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adapters/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ http/              # HTTP handlers, routing, validation, DTOs
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ handlers.go
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ routes.go
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dto.go
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ grpc/              # gRPC handlers (future)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ postgres/          # OrderRepository impl using pgx/sqlc
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ repository.go
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ queries.sql
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ kafka/             # EventBus impl (Kafka-specific producer/consumer)
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ producer.go
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ consumer.go
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ idempotency/       # IdempotencyStore impl (Postgres-backed)
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ store.go
‚îÇ   ‚îú‚îÄ‚îÄ database/                  # Database infrastructure
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres.go            # Connection pooling setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrate.go             # golang-migrate runner
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.go              # Health check helper
‚îÇ   ‚îú‚îÄ‚îÄ messaging/                 # Messaging infrastructure (tech-agnostic namespace)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka/                 # Kafka client setup, admin operations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.go
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin.go           # Topic creation, etc.
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.go
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware.go          # Message tracing, logging middleware
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/                 # Observability setup
‚îÇ       ‚îú‚îÄ‚îÄ otel.go                # OpenTelemetry initialization
‚îÇ       ‚îú‚îÄ‚îÄ metrics.go             # Prometheus metrics definitions
‚îÇ       ‚îú‚îÄ‚îÄ tracing.go             # Jaeger tracer setup
‚îÇ       ‚îî‚îÄ‚îÄ logging.go             # Structured logger (zerolog/zap)
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ docker/                    # Docker-specific config files
‚îÇ   ‚îî‚îÄ‚îÄ grafana/                   # Grafana dashboard JSONs
‚îú‚îÄ‚îÄ loadtest/
‚îÇ   ‚îî‚îÄ‚îÄ orders.js                  # k6 load test script
‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îú‚îÄ‚îÄ 000001_create_orders_table.up.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000001_create_orders_table.down.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000002_create_idempotency_table.up.sql
‚îÇ   ‚îî‚îÄ‚îÄ 000002_create_idempotency_table.down.sql
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îî‚îÄ‚îÄ README.md
```

**Key Design Principles:**
- **Ports** (interfaces) use generic, tech-agnostic names (`EventBus`, `IdempotencyStore`)
- **Adapters** (implementations) use specific names (`kafka/`, `postgres/`) for clarity
- **Infrastructure** packages (`database/`, `messaging/`) provide shared setup and helpers
- **Single idempotency location** under `orders/adapters/idempotency/` (not duplicated)

---

## üß≠ Design Goals

- **Tiny footprint** ‚Äì everything runs locally.
- **Real semantics** ‚Äì async events, retries, DLQs, idempotency.
- **Observability first** ‚Äì traces, metrics, logs are first-class.
- **Language focus** ‚Äì idiomatic Go with context propagation.
- **Safe failure** ‚Äì at-least-once delivery with deduplication.
---

## üß± License

MIT License ¬© 2025 ‚Äì *tbd project contributors*

---

## üß© References
- [OpenTelemetry Spec](https://opentelemetry.io/docs/)
- [Kafka Design Docs](https://kafka.apache.org/documentation/)
- [Go Context Propagation](https://pkg.go.dev/context)
- [Prometheus Docs](https://prometheus.io/docs/)
- [Grafana Dashboards](https://grafana.com/grafana/)
- [Jaeger Tracing](https://www.jaegertracing.io/)
